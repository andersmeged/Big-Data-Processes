{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Processes - exercise no.2:\n",
    "## <font color= green> Importing, exploring and visualising data </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to get datasets? \n",
    "\n",
    "https://www.gesis.org/en/home GESIS has many different types of surveys from Europe. Including Eurobarameter (which has many different topics and the European Value survey that is deployed every seven years. Create a login, go to services and check out the different types of surveys they have done under Finding and accessing data. \n",
    "\n",
    "https://www.kaggle.com/datasets Through Kaggle you will have access to over 50.000 public datasets \n",
    "\n",
    "Other possible sources for datasets include data.world and Google's dataset search\n",
    "\n",
    "https://data.world/search?q=type%3Adataset&type=resources\n",
    "\n",
    "https://datasetsearch.research.google.com/\n",
    "\n",
    "Scraping data using an API is another possibility, more on this later in the exerciese session!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import and load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with a dataset from GESIS it will come in a SAV file. To open a SAV file import pyreadstat as shown below, and create your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from pyreadstat) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ander\\anaconda3\\envs\\bdp_exercise\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat\n",
    "\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below put in your own path to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_spss(r\"C:\\Users\\Simone\\OneDrive\\4th semester DIM\\BDP TA\\Exercise 2\\value_survey.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with a dataset from GESIS can look a bit overwhelming, but through GESIS you will have access to documents explaining what the different columns mean, and how the survey questions were worded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue with a less overwhelming dataset and go through some more basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Auto-miss.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Open the dataset and examine it\n",
    "\n",
    "Using the .head() and .tail() functions to examine the dataset (like we saw last time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the .head() function shows the five first rows of the dataset. You can change number of rows shown by inserting a number\n",
    "#in the parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the .tail() function shows the five last rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get information on the datatype in each column through the .dtypes function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "int64 means that the data type of the column is an integer (a number without decimals)\n",
    "\n",
    "object means that the data type of that column is either string (line of text) or the column has a mixed of data types in it.\n",
    "\n",
    "float64 means that the data type of that column is a float (a number WITH decimals)\n",
    "\n",
    "As we can see the data type for the column horsepower is a float, whereas for acceleration it is an object (string or mixed). This is because the numbers in the acceleration column uses commas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the column names through .columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get this information and more through the **.info()** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What important information can you see in the **.info()** matrix above:\n",
    "- range length and index\n",
    "- columns: name, count, null, type\n",
    "- datatypes list - count per type\n",
    "- What columns are missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example the weight column only has 385 entries, whereas most of them have 392 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploration with summary statistics\n",
    "\n",
    "We can use the **.describe()** function to gain basic descriptive statistics about each column where it is applicable. \n",
    "For the **.describe()** function the 50% represents the median. However, just because it is applicable for some of the columns does not mean that it creates useful results for all the columns where it as applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all datasets are complete and contains missing values. It is important to locate any missing values in a dataset in order to later handle them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first count the values, which can be counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **.isna()** (Is NA?) function can be used to locate the missing values. It returns a boolean (True or False) for each datapoint in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the places where it says True in the dataset, then that is missing data values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn how to handle missing data in another week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Filtering (specific rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at all the cars is maybe too much so we can focus on one specific car in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset['column name'] returns only the specific column of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see how to select rows based on a specific value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['name'] == 'vw pickup']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or all the cars with ford in the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['name'].str.contains(r'ford')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also filter based on the row number and not on any name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to find out what is in row 48 of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[48]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Combining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the datasets we find do not contain enough information for our project. Consequently, we need to merge datasets in order to construct a dataset which contains all the necessary information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import dataset containing information about the colour of the cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour = pd.read_csv('car-colour.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the colour dataset there is a column named obsNo, we can use that column to merge the Colour column with the car dataset. Because in the cars dataset there is a column called obsNo as well. \n",
    "\n",
    "There are different ways of merging two dataframes, choosing \"outer\" is similar to a full outer join in SQL:\n",
    "https://www.w3schools.com/sql/sql_join_full.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carcolour= pd.merge(df, colour, on=['obsNo'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carcolour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to combine two datasets is the **.concat()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardata=[df,colour]\n",
    "carcolour2=pd.concat(cardata, sort=False, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carcolour2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1: \n",
    "How has concat combined the two datasets in comparison to merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also combine two datasets by using **.join()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.join(colour, on='obsNo',rsuffix=\"_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2:\n",
    "Why do you think that the last 6 rows show NaN for obsNo_r and colour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us look at the rows between row 120 and 130 (130 excluded)\n",
    "df.iloc[120:130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at obsNo 127? What is wrong? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the dataset on who eats the food we grow on Kaggle and load it into a variable called food. Show the first 10 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2:\n",
    "What is the data unit in the food dataset? The data unit is the instace that is described by all the variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the dataset on One-Sided violence \"Government of Angola - Civilians\" in the UCDP (Uppsala Conflict Data Programme) and load it into a variable called df (alias for dataframe). Find out the datatype in each column and the name of each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the UCDP collect their data on conflicts and how may this impact research based on this data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which additional datasets, reports etc. could prove beneficial for a research project based on the dataset on One-Sided Violence \"Government of Angola - Civilians\"? Describe how you would use the additional material in a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset \"car-maxspeed.csv\" into a variable called max-speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the \"carcolour\" dataset with the \"max-speed\" dataset in a new dataset called \"carcolourspeed\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "locate all cars with \"chevrolet\" in the name in the \"carcolourspeed\" dataset and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
